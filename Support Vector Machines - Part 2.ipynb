{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've only seen rbf kernel until now, there are other types too:\n",
    "\n",
    "Other types of kernels: \n",
    "http://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "\n",
    "The idea is that kernels are inner products in a transformed space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 The linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear kernel is, as we've seen, the default kernel and simply creates linear decision boundaries. The linear kernel is represented by the inner product of the $\\langle x, x' \\rangle$. It is not very important to really understand what's happening here, we just wanted to give the expression because you'll get the expressions for other kernels as well. As some kernels have additional parameters that can be specified, it is important to know about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two parameters when training an SVM with the Radial Basis Function: C and gamma. \n",
    "\n",
    "- The parameter C is common to all SVM kernels. By tuning the C parameter when using kernels, you can provide a trafe-off between misclassification of the training set and simplicity of the decision function. a high C will classify as many samples correctly as possible (and might potentially lead to overfitting).\n",
    "\n",
    "- Gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RBF kernel is specified as \n",
    "\n",
    "$$\\exp{(-\\gamma \\lVert  x -  x' \\rVert^2)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma has a strong effect on the results: gamma too large will lead to overfitting, a gamma which is too small will lead to underfitting (kind of like a simple linear boundary for a complex problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify a value for gamma using the attribute `gamma`. The default gamma value is \"auto\", if no other gamma is specified, gamma is set to 1/number_of_features (so, 0.5 if 2 classes, 0.333 when 3 classes, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 The Polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Polynomial kernel is specified as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$(\\gamma \\langle  x -  x' \\rangle+r)^d $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- d can be specified by the keyword `degree`. The default degree is 3. \n",
    "- r can be specified by the keyword `coef0`. The default is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 The Sigmoid kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sigmoid kernel is specified as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\tanh ( \\gamma\\langle  x -  x' \\rangle+r) $$\n",
    "\n",
    "This kernel is similar to the signoid function in logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVC, NuSVC and LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next to SVC, other functions exist in scikit-learn. \n",
    "\n",
    "### 2.1 NuSVC\n",
    "\n",
    "NuSVC is similar to SVC, but accepts slightly defferent parameters, and the mathematical formulation is also altered slightly. \n",
    "\n",
    "A new parameter $\\nu$ is introduced. The parameter controls the number of support vectors and training errors. $\\nu$ jointly creates an upper bound on training errors, and a lower bound on support vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like SVC, NuSVC implements the \"one-against-one\" approach when there are more than 2 classes. This means that when there are n classes, $\\dfrac{n*(n-1)}{2}$ classifiers are created, and each one classifies samples in 2 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 LinearSVC\n",
    "\n",
    "LinearSVC is similar to SVC, but instead of the \"one-versus-one\" method, a \"one-vs-rest\" method is used. So in this case, when there are n classes, just $n$ classifiers are created, and each one classifies samples in 2 classes, the one of interest, and all the other classes. This means that SVC generates more classifiers, so in cases with many classes, LinearSVC actually tends to scale better. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Probabilities and predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make predictions using support vector machines. The SVC decision function gives a probability score per class. This is not done by default, however, You'll need to set the `probability` argument equal to `True`. Scikit-learn internally performs cross-validations to compute the probabilities, so you can expect that setting `probability` to `True` makes the calculations longer. For large data sets, computation times can take considerable proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html\n",
    "    \n",
    "http://crsouza.com/2010/03/17/kernel-functions-for-machine-learning-applications/#linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jakevdp.github.io/PythonDataScienceHandbook/05.07-support-vector-machines.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/svm.html#svm-kernels --> mainly this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
